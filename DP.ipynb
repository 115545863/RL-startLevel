{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf62336",
   "metadata": {},
   "source": [
    "### 1. 动态规划\n",
    "\n",
    "基本思想是将一个待求解的问题分解成若干子问题，先解决子问题，然后通过子问题的解得到目标问题的解\n",
    "主要包括两种算法：**策略迭代**和**价值迭代**\n",
    "**策略迭代**\n",
    "- 策略评估：使用贝尔曼期望方程来得到一个策略的状态价值函数\n",
    "**价值迭代**：使用贝尔曼最优方程来进行动态规划，得到最终最有状态的价值\n",
    "\n",
    "#### 1.1 悬崖漫步问题\n",
    "悬崖漫步是一个非常经典的强化学习环境，它要求一个智能体从起点出发，避开悬崖行走，最终到达目标位置。如图 4-1 所示，有一个 4×12 的网格世界，每一个网格表示一个状态。智能体的起点是左下角的状态，目标是右下角的状态，智能体在每一个状态都可以采取 4 种动作：上、下、左、右。如果智能体采取动作后触碰到边界墙壁则状态不发生改变，否则就会相应到达下一个状态。环境中有一段悬崖，智能体掉入悬崖或到达目标状态都会结束动作并回到起点，也就是说掉入悬崖或者达到目标状态是终止状态。智能体每走一步的奖励是 −1，掉入悬崖的奖励是 −100。\n",
    "\n",
    "![image-2.png](picture/dp-1.png)\n",
    "\n",
    "下面是环境的具体代码设计，其中涉及到了一个坐标压缩和转换的问题，具体公式和逻辑如下所示\n",
    "\n",
    "![image-2.png](picture/dp-2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f68dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置悬崖漫步环境\n",
    "import copy\n",
    "\n",
    "class CliffwalkingEnv:\n",
    "    def __init__(self, col=12,row=4):\n",
    "        self.col = col\n",
    "        self.row = row\n",
    "        self.p = self.createP()\n",
    "    def createP(self):\n",
    "        # 初始化\n",
    "        p = [[[]for j in range(4)] for i in range(self.row*self.col)]\n",
    "        # 初始化动作：向上；向下；向左；向右\n",
    "        change = [[0,-1],[0,1],[-1,0],[1,0]]\n",
    "        for r in range(self.row):\n",
    "            for c in range(self.col):\n",
    "                for a in range(4):\n",
    "                    # 如果位置掉下了悬崖或者在目标位置，无法继续交互，奖励为0\n",
    "                    if r == self.row -1 and c>0:\n",
    "                        # 如果是非起点的最后一行，说明不是悬崖就是目标节点\n",
    "                        p[r*self.c+c][a] = [(1,r*self.col+c,0,True)]\n",
    "                        \n",
    "                        continue\n",
    "                                        # 其他位置\n",
    "                    next_x = min(self.col - 1, max(0, c + change[a][0]))\n",
    "                    next_y = min(self.row - 1, max(0, r + change[a][1]))\n",
    "                    # 状态的变换，这个地方做的是一个坐标映射，把二维映射到一维\n",
    "                    # 上面公式的应用\n",
    "                    next_state = next_y * self.col + next_x\n",
    "                    reward = -1\n",
    "                    done = False\n",
    "                    # 下一个位置在悬崖或者终点：\n",
    "                    if next_y == self.row -1 and next_x>0:\n",
    "                        done = True\n",
    "                        if next_x!=self.col:# 下一个位置是悬崖：\n",
    "                            reward = -100\n",
    "                    p[r * self.col + c][a] = [(1, next_state, reward, done)]\n",
    "        return p\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce00e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
